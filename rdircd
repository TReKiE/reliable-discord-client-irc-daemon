#!/usr/bin/env python3

import itertools as it, operator as op, functools as ft
import os, sys, io, stat, re, time, secrets, enum, json
import contextlib, asyncio, socket, signal, inspect, traceback
import hashlib, base64, random, unicodedata, urllib.parse
import configparser, tempfile, datetime as dt, pathlib as pl
import collections as cs, collections.abc as cs_abc
import logging, logging.handlers

import aiohttp


err_fmt = lambda err: '[{}] {}'.format(err.__class__.__name__, err)

class LogMessage:
	def __init__(self, fmt, a, k): self.fmt, self.a, self.k = fmt, a, k
	def __str__(self): return self.fmt.format(*self.a, **self.k) if self.a or self.k else self.fmt

class LogStyleAdapter(logging.LoggerAdapter):
	def __init__(self, logger, extra=None): super().__init__(logger, extra or {})
	def log(self, level, msg, *args, **kws):
		if not self.isEnabledFor(level): return
		log_kws = dict((k, kws.pop(k, None)) for k in ['extra', 'exc_info'])
		if not isinstance(log_kws['extra'], dict): log_kws['extra'] = dict(extra=log_kws['extra'])
		msg, kws = self.process(msg, kws)
		self.logger._log(level, LogMessage(msg, args, kws), (), **log_kws)

class LogFuncHandler(logging.Handler):
	def __init__(self, func):
		super().__init__()
		self.func, self.locked = func, False
	def emit(self, record):
		if self.locked: return # to avoid logging-of-logging loops, assuming sync call
		self.locked = True
		try: self.func(self.format(record))
		# except Exception: self.handleError(record) # too noisy
		except Exception as err: log_bak.exception('LogFuncHandler failed - {}', err_fmt(err))
		finally: self.locked = False

class LogEmptyMsgFilter(logging.Filter):
	def filter(self, record):
		msg = record.msg
		return bool(msg if isinstance(msg, str) else msg.fmt)
log_empty_filter = LogEmptyMsgFilter()

class LogProtoFormatter(logging.Formatter):
	last_ts = last_rec = last_reltime = None
	def format(self, record):
		if id(record) != self.last_rec:
			reltime = (record.created - self.last_ts) if self.last_ts else 0
			self.last_reltime = '{}{:,.3f}'.format('+' if reltime >= 0 else '', reltime)
			self.last_ts, self.last_rec = record.created, id(record)
		record.reltime = self.last_reltime
		record.asctime = time.strftime(
			'%Y-%m-%dT%H:%M:%S', time.localtime(record.created) )
		record.asctime += f'.{record.msecs:03.0f}'
		if record.name.startswith('proto.'): record.name = record.name[6:]
		try:
			st, msg = record.extra
			if isinstance(msg, bytes): msg = json.dumps(msg.decode())
		except Exception as err:
			st, msg = 'err', err_fmt(err)
			log_bak.exception('LogProtoFormatter failed - {}', msg)
		record.message = f'{st} :: {msg}'
		return self.formatMessage(record)

class LogFileHandler(logging.handlers.RotatingFileHandler):
	def set_file(self, path):
		self.stream, self.baseFilename = None, os.path.abspath(os.fspath(path))

class LogLevelCounter(logging.Handler):
	def __init__(self, *args, **kws):
		super().__init__(*args, **kws)
		self.counts = cs.Counter()
	def emit(self, record): self.counts[record.levelname.lower()] += 1

get_logger = lambda name: LogStyleAdapter(logging.getLogger(name))
log_bak = get_logger('fallback')


def monkey_patch_aiohttp_debug(log):
	# This is obviously very fragile and will break eventually
	import aiohttp.http_writer, aiohttp.client_reqrep

	@contextlib.contextmanager
	def log_req(part):
		if not log.isEnabledFor(logging.DEBUG): return
		try:
			log.debug('', extra=(' >>', f'req :: {part} start'))
			yield
			log.debug('', extra=(' >>', f'req :: {part} end'))
		except Exception as err:
			err = err_fmt(err)
			log.exception( 'Protocol logging failed: {}',
				err, extra=('xxx', f'req :: {part} FAIL :: {err}') )

	async def write_headers(self, status_line, headers) -> None:
		buf = aiohttp.http_writer._serialize_headers(status_line, headers)
		with log_req('headers'):
			for line in buf.decode().strip().splitlines(): log.debug('', extra=('  >', f'  {line}'))
		self._write(buf)
	aiohttp.http_writer.StreamWriter.write_headers = write_headers

	write_bytes_base = aiohttp.client_reqrep.ClientRequest.write_bytes
	async def write_bytes(self, writer, conn):
		if isinstance(self.body, aiohttp.payload.Payload):
			with log_req('body'): log.debug('', extra=('  >', self.body._value))
		await write_bytes_base(self, writer, conn)
	aiohttp.client_reqrep.ClientRequest.write_bytes = write_bytes


def sockopt_resolve(prefix, v):
	prefix = prefix.upper()
	for k in dir(socket):
		if not k.startswith(prefix): continue
		if getattr(socket, k) == v: return k[len(prefix):]
	return v

str_norm = lambda v: unicodedata.normalize('NFKC', v.strip()).casefold()

def str_part(s, sep, default=None):
	'Examples: str_part("user@host", "<@", "root"), str_part("host:port", ":>")'
	c = sep.strip('<>')
	if sep.strip(c) == '<': return (default, s) if c not in s else s.split(c, 1)
	else: return (s, default) if c not in s else s.rsplit(c, 1)

def str_repr(s, prefix=False, max_len=50, ext=' ...[{s_len}]'):
	if isinstance(s, bytes): s = s.decode('utf-8', 'replace')
	if not isinstance(s, str): s = str(s)
	s_len, s_repr, ext_len = f'{len(s):,d}', repr(s)[1:-1], len(ext.format(s_len=9999))
	if max_len > 0 and len(s_repr) > max_len:
		s_len = f'{max_len}/{s_len}'
		s_repr = s_repr[:max_len - ext_len] + ext.format(s_len=s_len)
	return (s_len, s_repr) if prefix else s_repr


def str_hash(s, c=None, key='rdircd'):
	s = base64.urlsafe_b64encode(
			hashlib.blake2s(str(s).encode(), key=key.encode()).digest() )\
		.decode().replace('-', '').replace('_', '').replace('=', '')
	if c is None: return s
	if len(s) < c: s = str_hash(s, c, key)
	return s[:c]

def tuple_hash(t, c=None, key='rdircd'):
	s = '\0'.join(str(v).replace('\0', '\0\0') for v in t)
	return str_hash(s, c=c, key=key)


def force_list(v):
	if not v: v = list()
	elif isinstance(v, cs_abc.ValuesView): v = list(v)
	elif not isinstance(v, list): v = [v]
	return v

def dict_update(d, du_iter=None, sync=True):
	keys_old, du = set(d.keys()), dict()
	if du_iter: du.update(du_iter)
	d.update(du)
	if sync: return dict((k, d.pop(k)) for k in keys_old.difference(du))

@contextlib.contextmanager
def safe_replacement(path, *open_args, mode=None, **open_kws):
	path = str(path)
	if mode is None:
		try: mode = stat.S_IMODE(os.lstat(path).st_mode)
		except OSError: pass
	open_kws.update( delete=False,
		dir=os.path.dirname(path), prefix=os.path.basename(path)+'.' )
	if not open_args: open_kws['mode'] = 'w'
	with tempfile.NamedTemporaryFile(*open_args, **open_kws) as tmp:
		try:
			if mode is not None: os.fchmod(tmp.fileno(), mode)
			yield tmp
			if not tmp.closed: tmp.flush()
			os.rename(tmp.name, path)
		finally:
			try: os.unlink(tmp.name)
			except OSError: pass

def token_bucket(spec, negative_tokens=False):
	'''Spec: { interval_seconds: float | float_a/float_b }[:burst_float]
			Examples: 1/4:5 (interval=0.25s, rate=4/s, burst=5), 5, 0.5:10, 20:30.
		Expects a number of tokens (can be float, default: 1)
			and *always* subtracts these.
		Yields either None if there's enough
			tokens or delay (in seconds, float) until when there will be.'''
	try:
		try: interval, burst = spec.rsplit(':', 1)
		except (ValueError, AttributeError): interval, burst = spec, 1.0
		else: burst = float(burst)
		if isinstance(interval, str):
			try: a, b = interval.split('/', 1)
			except ValueError: interval = float(interval)
			else: interval = float(a) / float(b)
		if min(interval, burst) < 0: raise ValueError()
	except: raise ValueError('Invalid format for rate-limit: {!r}'.format(spec))
	# log.debug('tbf parameters: interval={:.1f}, burst={:.1f}', interval, burst)
	tokens, rate, ts_sync = burst, interval**-1, time.monotonic()
	val = (yield) or 1
	while True:
		ts = time.monotonic()
		ts_sync, tokens = ts, min(burst, tokens + (ts - ts_sync) * rate)
		val, tokens = (None, tokens - val) if tokens >= val else\
			((val - tokens) / rate, (tokens - val) if negative_tokens else tokens)
		val = (yield val) or 1

async def await_wrap(res):
	if inspect.isawaitable(res): res = await res
	return res

async def task_cancel(task_list):
	'Cancel and await a task or a list of such, which can have empty values mixed-in.'
	if inspect.isawaitable(task_list): task_list = [task_list]
	task_list = list(filter(None, task_list))
	for task in task_list:
		with contextlib.suppress(asyncio.CancelledError): task.cancel()
	for task in task_list:
		with contextlib.suppress(asyncio.CancelledError): await task


class StacklessContext:
	'''Like AsyncContextStack, but for tracking tasks that
		can finish at any point without leaving stack frames.'''

	def __init__(self, log): self.tasks, self.log = dict(), log
	async def __aenter__(self): return self
	async def __aexit__(self, *err):
		if self.tasks:
			task_list, self.tasks = self.tasks.values(), None
			await task_cancel(task_list)
	async def close(self): await self.__aexit__(None, None, None)

	def add_task(self, coro, run_after=None):
		'Start task eating its own tail, with an optional success-only callback'
		task_id = None
		async def _task_wrapper(coro=coro):
			try:
				await coro
				if run_after:
					coro = run_after()
					if asyncio.isawaitable(coro): await coro
			except asyncio.CancelledError: pass
			except Exception as err:
				self.log.exception('Background task failed: {} - {}', coro, err_fmt(err))
			finally:
				assert task_id is not None, task_id
				if self.tasks: self.tasks.pop(task_id, None)
		task = asyncio.create_task(_task_wrapper())
		task_id = id(task)
		self.tasks[task_id] = task
		return task
	add = add_task


class FixedOffsetTZ(dt.tzinfo):
	_offset = _name = None
	@classmethod
	def from_offset(cls, name=None, delta=None, hh=None, mm=None):
		self = cls()
		if delta is None: delta = dt.timedelta(hours=hh or 0, minutes=mm or 0)
		self._name, self._offset = name, delta
		return self
	def utcoffset(self, dt): return self._offset
	def tzname(self, dt): return self._name
	def dst(self, dt, ZERO=dt.timedelta(0)): return ZERO
	def __repr__(self): return '<FixedOffset {!r}>'.format(self._name)

TZ_UTC = FixedOffsetTZ.from_offset('UTC')

def datetime_to_float(dt, _ts0=dt.datetime(1970, 1, 1, tzinfo=TZ_UTC)):
	return (dt - _ts0).total_seconds()

def parse_iso8601( spec,
		tz_default=TZ_UTC, to_float=True, validate=False,
		_re=re.compile(
			r'(\d{4})-(\d{2})-(\d{2})(?:[T ](\d{2}):(\d{2}))?'
			r'(?::(?P<s>\d{2})(?:\.(?P<us>\d+))?)?\s*(?P<tz>Z|[-+]\d{2}:\d{2})?' ) ):
	m = _re.search(spec)
	if not m: raise ValueError(spec)
	if validate: return
	if m.group('tz'):
		tz = m.group('tz')
		if tz == 'Z': tz = TZ_UTC
		else:
			k = {'+':1,'-':-1}[tz[0]]
			hh, mm = ((int(n) * k) for n in tz[1:].split(':', 1))
			tz = FixedOffsetTZ.from_offset(hh=hh, mm=mm)
	else: tz = tz_default
	ts_list = list(m.groups()[:5])
	if not ts_list[3]: ts_list[3] = ts_list[4] = 0
	ts_list = it.chain( map(int, ts_list),
		[int(m.group('s') or 0), int(m.group('us') or 0)] )
	# Minutes, seconds, microseconds get discarded here!
	ts = dt.datetime.strptime(
		'{:04d}-{:02d}-{:02d} {:02d}:{:02d}:{:02d}.{:06d}'.format(*ts_list),
		'%Y-%m-%d %H:%M:%S.%f' )
	assert tz
	ts = ts.replace(tzinfo=tz)
	return ts if not to_float else datetime_to_float(ts)

def ts_iso8601(ts, ms=3, to_str=True, human=False):
	if not isinstance(ts, dt.datetime):
		ts = ( dt.datetime.utcfromtimestamp(ts)
			if not human else dt.datetime.fromtimestamp(ts) )
	if not human: ts = ts.replace(tzinfo=TZ_UTC)
	if ts.year > 2030: raise ValueError(ts) # sanity check
	if not to_str: return ts
	if human: return ts.strftime(f'%Y-%m-%d %H:%M:%S')
	ts_ext = f'{ts.microsecond:06d}'[:ms]
	if ts_ext: ts_ext = f'.{ts_ext}'
	return ts.strftime(f'%Y-%m-%dT%H:%M:%S') + ts_ext + 'Z'


def iter_gather(cls, cache=False):
	'''Auto-gathers iterator function result into cls.
		cache=True will memoize function, allowing *args only,
			and pass cache_track func as a second argument to all calls.
		cache_track usage:
			ct(d) - any shallow changes to adict "d" will drop result cache for this call.
			ct(d, 'key1 key2 ...'), ct(d, [k1, k2, ...])
				Any changes to specified keys of "d" will drop result cache for this call.
				If any of these keys have adict value, shallow changes to it will propagate.'''
	def _cls_wrapper(func):
		@ft.wraps(func)
		def _wrapper(self, *args, **kws):
			if not cache: return cls(func(self, *args, **kws))
			if kws: raise ValueError(kws)
			k = (func.__qualname__, *args)
			if k not in iter_gather.cache:
				cache_track = ft.partial(iter_gather_track, k)
				args = [cache_track, *args]
				iter_gather.cache[k] = cls(func(self, *args, **kws))
			return iter_gather.cache[k]
		return _wrapper
	return _cls_wrapper

def iter_gather_cb(cache_k, keys, k, v):
	if keys and k not in keys: return
	iter_gather.cache.pop(cache_k, None)

def iter_gather_track(cache_k, o, keys=None):
	if not isinstance(o, adict): raise TypeError(o)
	if isinstance(keys, str): keys = keys.split()
	o._cache_cb_add( cache_k,
		ft.partial(iter_gather_cb, cache_k, keys) )
	for k in keys or list():
		if isinstance(o.get(k), adict): iter_gather_track(cache_k, o[k])

iter_gather.cache = dict()


class adict(cs.UserDict):
	__slots__ = 'data', '_cache_cb'

	def __init__(self, *args, **kws):
		self._cache_cb = None
		super().__init__(*args, **kws)
		self._make(self)

	def _make(self, v):
		if v is self: v.update((k, self._make(v)) for k,v in v.items())
		elif type(v) is dict: v = adict(v)
		elif isinstance(v, (tuple, list)): v = type(v)(map(self._make, v))
		return v

	def _cache_cb_add(self, cb_k, cb):
		if self._cache_cb is None: self._cache_cb = dict()
		self._cache_cb[cb_k] = cb
	def _cache_cb_check(self, k, v=...):
		if not self._cache_cb: return
		for cb in self._cache_cb.values(): cb(k, v)
		self._cache_cb.clear()

	def __getattr__(self, k):
		if k not in self.__slots__: return self[k]
		return self.__getattribute__(k)
	def __setattr__(self, k, v):
		if k not in self.__slots__: self[k] = v
		return super().__setattr__(k, v)

	def __delattr__(self, k, v): del self[k]
	def __setitem__(self, k, v):
		super().__setitem__(k, v)
		self._cache_cb_check(k, v)
	def __delitem__(self, k):
		super().__delitem__(k)
		self._cache_cb_check(k)



class IRCProtocolError(Exception): pass
class IRCProtocolArgsError(IRCProtocolError): pass
class IRCBridgeSignal(Exception): pass

class IRCProtocol:

	# Extensive lists of modes are copied from freenode to make clients happy
	feats_modes = 'DOQRSZaghilopswz CFILMPQSbcefgijklmnopqrstvz'
	feats_support = ( 'AWAYLEN=200 CASEMAPPING=ascii'
		' CHANLIMIT=#:512 CHANTYPES=# CHANMODES=eIbq,k,flj,CFLMPQScgimnprstz'
		' CHANNELLEN=80 ELIST=C NETWORK=rdircd NICKLEN=64'
		' PREFIX=(ov)@+ SAFELIST STATUSMSG=@+ TOPICLEN=390 USERLEN=32' ).split()

	@classmethod
	def factory_for_bridge(cls, rdircd):
		def _wrapper():
			try: return cls(rdircd)
			except Exception as err:
				log = get_logger('rdircd.irc.factory')
				log.exception('Failed to initialize ircd protocol: {}', err_fmt(err))
				log.critical('Stopping daemon due to unhandled protocol error')
				loop.stop()
		return _wrapper

	def __init__(self, rdircd):
		self.bridge, self.loop, self.conf = rdircd, rdircd.loop, rdircd.conf
		self.log = get_logger('rdircd.irc.init')
		self.transport, self.buff, self.recv_queue = None, b'', asyncio.Queue()
		self._cmd_cache, self.st = dict(), adict(
			nick=None, user=None, pw=None, pw_hash=None,
			host=None, auth=False, cap_neg=False, chans=set() )
		if self.conf.irc_password:
			salt = os.urandom(8)
			self.st.pw_hash = salt, hashlib.blake2b(
				self.conf.irc_password.encode(), salt=salt ).digest()


	def connection_made(self, tr):
		host, port = tr.get_extra_info('peername')[:2]
		conn_id = tuple_hash([host, port], 3)
		self.log_proto = get_logger(f'proto.irc.{conn_id}')
		self.log_proto.debug( '--- -conn- {} {} {}',
			host, port, conn_id, extra=('---', f'conn {host} {port}') )
		self.log = get_logger(f'rdircd.irc.{conn_id}')
		self.log.debug('Connection from {} {} [{}]', host, port, conn_id)
		self.transport, self.st.host = tr, host
		self.send('NOTICE * :*** rdircd ready')
		self.bridge.irc_conn_new(self)
		self.bridge.cmd_delay(self.recv_queue_proc)

	def data_received(self, data):
		self.buff += data
		while b'\n' in self.buff:
			line, self.buff = self.buff.split(b'\n', 1)
			if not line.strip(): continue
			line_len, line_repr = self._repr(line, True)
			self.log_proto.debug( '<<  [{} {}] {}',
				self.st.nick or '---', line_len, line_repr, extra=('<< ', line) )
			if not line.strip(): continue
			if self.recv_queue: self.recv_queue.put_nowait(line)
			else: self.log.error('Data after recv queue stopped: {!r}', line)

	def eof_received(self): pass
	def connection_lost(self, err):
		reason = err or 'closed cleanly'
		if isinstance(reason, Exception): reason = err_fmt(reason)
		self.log_proto.debug('--- -close- :: {}', reason, extra=('---', 'close'))
		self.log.debug('Connection lost: {}', reason)
		if self.recv_queue: self.recv_queue.put_nowait(StopIteration)
		self.bridge.irc_conn_lost(self)

	def data_send(self, data):
		data_len, data_repr = self._repr(data, True)
		self.log_proto.debug( ' >> [{} {}] {}',
			self.st.nick or '---', data_len, data_repr, extra=(' >>', data) )
		self.transport.write(data)


	def _repr(self, data, prefix=False, max_len=None, ext=' [{data_len}]'):
		'Binary-friendly version of str_repr().'
		if isinstance(data, str): data = data.encode()
		if max_len is None: max_len = self.conf.debug_proto_cut
		data_len, data_repr, ext_len = f'{len(data):,d}', repr(data)[2:-1], len(ext)
		if max_len > 0 and len(data_repr) > max_len:
			data_len = f'{max_len}/{data_len}'
			data_repr = data_repr[:max_len - ext_len] + ext.format(data_len=data_len)
		return (data_len, data_repr) if prefix else data_repr

	def _parse(self, line):
		if isinstance(line, bytes): line = line.decode()
		m = adict(line=line, params=list())
		for k in '@tags', ':src':
			pre, k = k[0], k[1:]
			if line.startswith(pre):
				try: m[k], line = line.split(' ', 1)
				except ValueError:
					raise IRCProtocolLineError(line) from None
				line = line.lstrip(' ')
			else: m[k] = None
		while True:
			if line.startswith(':'):
				m.params.append(line[1:])
				break
			if ' ' in line:
				param, line = line.split(' ', 1)
				line = line.lstrip(' ')
			else: param, line = line, ''
			m.params.append(param)
			if not line: break
		if m.params: m.cmd, m.params = m.params[0].lower(), m.params[1:]
		else: raise IRCProtocolLineError(line)
		return m

	def send(self, line_or_code, *args, max_len=450, auto_split=True):
		line = line_or_code
		if isinstance(line, int): line = f'{line:03d} {self.st.nick or "*"}'
		if args: line += ' ' + ' '.join(map(str, args))
		if isinstance(line, str): line = line.encode()
		line = line.rstrip(b'\r\n')
		if b'\n' in line or len(line) > max_len:
			if auto_split:
				m = self._parse(line)
				if m.cmd in ['privmsg', 'notice']: return self.send_split_msg(m)
			if len(line) > max_len:
				self.log.warning('Sending line with >{}B: {!r}', max_len, self._repr(line))
		if b'\n' in line: raise IRCProtocolError(f'Line with newlines: {line!r}')
		line += b'\r\n'
		self.data_send(line)

	def send_split_msg(self, m, max_len=300):
		dst, line = m.params
		pre = f'{m.cmd.upper()} {dst}'
		if m.src: pre = f'{m.src} {pre}'
		if '\n' in line:
			for line in line.split('\n'): self.send(pre, f':{line.rstrip()}')
			return
		line, ws = '', re.findall(r'(\S+)(\s*)', line)
		for w, sep in ws:
			if line.strip() and len(line) + len(w) > max_len:
				self.send(pre, f':{line.rstrip()}', auto_split=False)
				line = sep_last
			sep_last, line = sep, line + w + sep
		if line.strip(): self.send(pre, f':{line.rstrip()}', auto_split=False)

	async def recv_queue_proc(self):
		try:
			while True:
				line = await self.recv_queue.get()
				if line is StopIteration: break
				try: await self.recv(line)
				except Exception as err:
					self.log.exception(f'Failed to parse line: {line}')
		finally: self.recv_queue = None

	async def recv(self, line_raw):
		if isinstance(line_raw, str): line = line_raw
		else:
			try: line = line_raw.decode().strip()
			except UnicodeDecodeError:
				return self.log.error('Failed to decode line as utf-8: {!r}', self._repr(line_raw))
		try: m = self._parse(line)
		except IRCProtocolLineError:
			return self.log.error('Line protocol error: {!r}', self._repr(line_raw))
		cmd_cache = self._cmd_cache.get(m.cmd)
		if cmd_cache: cmd_func, cmd_ps_n = cmd_cache
		else:
			cmd_func, cmd_ps_n = getattr(self, f'recv_cmd_{m.cmd}', None), 0
			if cmd_func:
				args = list(inspect.signature(cmd_func).parameters.values())
				cmd_ps_n = len(args)
				if cmd_ps_n == 1 and args[0].annotation == 'msg': cmd_ps_n = None
				else: cmd_ps_n = cmd_ps_n - sum(1 for p in args if p.default is not p.empty), cmd_ps_n
			self._cmd_cache[m.cmd] = cmd_func, cmd_ps_n
		if not cmd_func:
			self.log.error('Unhandled cmd: {!r}', self._repr(line_raw))
			return self.send(421, ':Unknown command')
		if not self.check_access(m.cmd):
			return self.log.error('Out-of-order cmd: {!r}', self._repr(line_raw))
		if cmd_ps_n is None: await await_wrap(cmd_func(m))
		else:
			(a, b), n = cmd_ps_n, len(m.params)
			if not a <= n <= b:
				self.log.error( 'Command/args'
					' mismatch [{} vs {}-{}]: {!r}', n, a, b, self._repr(line) )
				return self.send(461, ':Incorrect command parameters')
			try: await await_wrap(cmd_func(*m.params))
			except Exception as err:
				self.send(400, m.cmd.upper(), f':BUG - Internal Error - {err_fmt(err)}')
				self.log.exception('Error processing message: {}', m)

	def check_access(self, cmd):
		if self.st.cap_neg: return cmd in ['cap', 'quit']
		if not self.st.auth:
			res = cmd in ['cap', 'user', 'nick', 'pass', 'quit', 'ping']
			if not res: self.send(451, ':You have not registered')
			return res
		res = cmd not in ['user', 'pass']
		if not res: self.send(462, ':You may not reregister')
		return res

	# chan_spec=#some-channel, chan_name=some-channel
	_csc = lambda c: c.startswith('#')
	chan_spec_check = staticmethod(_csc)
	chan_spec = staticmethod(lambda name,_csc=_csc: name if _csc(name) else f'#{name}')
	chan_name = staticmethod(lambda chan,_csc=_csc: chan if not _csc(chan) else chan[1:])


	def recv_cmd_ping(self, server, server_dst=None):
		self.send(f'PONG {self.bridge.server_host}')

	def recv_cmd_cap(self, sub, caps=''):
		sub = sub.lower()
		if sub == 'ls':
			self.send('CAP * LS :')
			if caps == '302': self.st.cap_neg = True
		elif sub == 'list': self.send('CAP * LIST :')
		elif sub == 'req':
			self.st.cap_neg = True
			reject = set(c for c in caps.split() if not c.startswith('-'))
			if reject: self.send(f'CAP * NAK :{caps}')
			else: self.send(f'CAP * ACK :{caps}')
		elif sub == 'end': self.st.cap_neg = False

	def recv_cmd_pass(self, pw):
		self.st.pw = pw
		self.check_auth_done()
	def recv_cmd_user(self, name, a, b, real_name):
		self.st.update(user=name, real_name=real_name)
		self.check_auth_done()
	def recv_cmd_nick(self, nick):
		if not re.search(r'^[a-zA-Z-._]+$', nick):
			return self.send(432, nick, ':Erroneus nickname')
		if self.bridge.cmd_conn(nick):
			return self.send(433, nick, ':Nickname is already in use')
		self.st.nick = nick
		if self.st.auth and self.st.nick:
			self.send(f':{self.st.nick} NICK {nick}')
		self.check_auth_done()

	def check_auth_done(self):
		# Delay is to avoid trivial bruteforcing
		self.bridge.cmd_delay('irc_auth', self.check_auth_done_delayed)

	def check_auth_done_delayed(self):
		if self.st.auth: return
		if not (self.st.nick and self.st.user): return
		if self.st.pw_hash:
			salt, pw_hash = self.st.pw_hash
			if not secrets.compare_digest( pw_hash,
					hashlib.blake2b((self.st.pw or '').encode(), salt=salt).digest() ):
				return self.send(464, ':Password incorrect')
		self.st.auth = True
		self.send('NOTICE * :*** registration completed')
		self.send(1, f':Welcome to the rdircd discord-irc bridge, {self.st.nick}')
		self.send(2,
			f':Your host is {self.bridge.server_host},'
			f' running rdircd {self.bridge.server_ver}' )
		self.send(3, ':This server was created at {}'.format(
			self.bridge.server_ts.strftime('%Y-%m-%d %H:%M:%S UTC') ))
		self.send(4, f'{self.bridge.server_host} rdircd-{self.bridge.server_ver} {self.feats_modes}')
		self.send_feats()
		self.send_stats()
		self.send_motd()

	def send_feats(self, msg_feats_max=10, msg_len_max=200):
		feat_line, ext = list(), ':are supported by this server'
		for feat in it.chain(self.feats_support, [None]):
			if feat: feat_line.append(feat)
			n, msg_len = len(feat_line), sum((len(f)+1) for f in feat_line)
			if feat_line and (not feat or n >= msg_feats_max or msg_len >= msg_len_max):
				self.send(5, ' '.join(feat_line), ext)
				feat_line.clear()

	def send_stats(self):
		s = self.bridge.irc_conn_stats()
		self.send(251, f':There are {s.auth} users and 0 invisible on {s.servers} server(s)')
		self.send(252, f'{s.op} :IRC Operators online')
		self.send(253, f'{s.unknown} :unknown connection(s)')
		self.send(254, f'{s.chans} :channels formed')
		self.send(255, f':I have {s.total} client(s) and {s.servers} server(s)')
		self.send( 265, f'{s.total} {s.total_max}',
			f':Current local users {s.total}, max {s.total_max}' )
		self.send( 266, f'{s.total} {s.total_max}',
			f':Current global users {s.total}, max {s.total_max}' )

	def send_motd(self): self.send(422, ':MOTD File is missing')

	def recv_cmd_quit(self, reason=None):
		self.send('QUIT :Client quit')
		self.send('ERROR :Closing connection (client quit)')
		self.transport.close()

	def req_chan_info(self, chan, cm=None, check=True):
		if not self.chan_spec_check(chan):
			return self.send(403, chan, ':No such channel')
		if not cm: cm = self.bridge.cmd_chan_map()
		c = cm.get(self.chan_name(chan))
		if c: return c
		if check: self.send(403, chan, ':No such channel')

	def recv_cmd_join(self, chan, key=None):
		if chan == '0': return self.recv_cmd_part(','.join(self.st.chans))
		chan_list, chan_map = chan.split(','), self.bridge.cmd_chan_map()
		for chan in chan_list:
			c = self.req_chan_info(chan, cm=chan_map, check=False)
			self.send(f':{self.st.nick} JOIN {chan}')
			self.send_topic(chan, c=c)
			self.send_names(chan, own=True, c=c)
			self.st.chans.add(c.name if c else self.chan_name(chan))

	def recv_cmd_part(self, chan, reason=None):
		chan_list, chan_map = chan.split(','), self.bridge.cmd_chan_map()
		for chan in chan_list:
			c = self.req_chan_info(chan, cm=chan_map, check=False)
			if not c: continue
			if c.name not in self.st.chans:
				self.send(442, chan, ':You are not on that channel')
			else:
				self.st.chans.remove(c.name)
				self.send(f'PART {chan}')

	async def recv_cmd_topic(self, chan, topic=None):
		if not self.chan_spec_check(chan):
			return self.send(403, chan, ':No such channel')
		if not topic:
			self.send_topic(chan)
			return await self.bridge.irc_topic_cmd(self, chan)
		try: await self.bridge.irc_topic_cmd(self, chan, topic)
		except IRCBridgeSignal as err: self.send(482, chan, f':{err}')

	def send_topic(self, chan, c=...):
		if c is ...: c = self.req_chan_info(chan)
		if not (c and c.topic): self.send(331, chan, ':No topic is set')
		else:
			self.send(332, chan, f':{c.topic}')
			topic_src = c.get('topic_src')
			if topic_src: self.send(333, chan, topic_src.nick, int(topic_src.ts))

	def recv_cmd_names(self, chan):
		chan_list = chan.split(',')
		for chan in chan_list: self.send_names(chan)

	def send_names(self, chan, own=False, c=..., msg_len_max=200):
		if c is ...: c = self.req_chan_info(chan)
		name_line, names = list(), filter(None, c.names) if c else list()
		for name in it.chain(names, [None]):
			if name:
				if name == self.st.nick: own = False
				name_line.append(name)
			elif own: name_line.append(self.st.nick)
			if name_line and (
					not name or sum(len(n)+1 for n in name_line) > msg_len_max ):
				self.send(353, '=', chan, ':' + ' '.join(name_line))
				name_line.clear()
		self.send(366, chan, ':End of /NAMES list')

	def recv_cmd_mode(self, target, mode=None, mode_args=None):
		if self.chan_spec_check(target):
			chan = target
			c = self.req_chan_info(chan, check=False)
			self.send(324, chan, '+cnrt')
			if c: chan_ts = int(c.ts_created)
			else:
				if self.chan_name(chan) not in self.st.chans:
					return self.send(403, chan, ':No such channel')
				chan_ts = int(time.time())
			self.send(329, chan, chan_ts)
		else:
			if target != self.st.nick:
				return self.send(502, ':No access to modes of other users')
			self.send(221, ':+w')

	def recv_cmd_list(self, chan=None, cond=None):
		# XXX: searching for new channels (ELIST=C) might be nice to have
		self.send(321, 'Channel :Users  Name')
		for c in self.bridge.cmd_chan_map().values():
			self.send(322, self.chan_spec(c.name), len(c.names), f':{c.topic}')
		self.send(321, ':End of /LIST')

	def recv_cmd_motd(self, target=None): self.send_motd()

	def recv_cmd_version(self, target=None):
		self.send(351, self.bridge.server_ver, 'rdircd', ':rdircd discord-to-irc bridge')
		self.send_feats()

	def recv_cmd_userhost(self, nick):
		if str_norm(nick) == str_norm(self.st.nick):
			self.send(302, f':{nick}=+~{self.st.user}@{self.st.host}')
		else: self.send(401, nick, ':No such nick/channel') # XXX: info for discord nicks

	# def recv_cmd_whois(self, nick): # XXX: RPL_*WHOIS* + discord info via notices?

	def recv_cmd_privmsg(self, target, text):
		self.cmd_msg(self.st.nick, target, text, skip_self=True)

	def recv_cmd_notice(self, target, text):
		self.cmd_msg(self.st.nick, target, text, notice=True, skip_self=True)

	def cmd_msg(self, src, target, text, notice=False, skip_self=False, msg_type=None):
		if not msg_type: msg_type = 'PRIVMSG' if not notice else 'NOTICE'
		if self.chan_spec_check(target):
			chan = target
			if not notice: c = self.req_chan_info(chan)
			else: c = self.bridge.cmd_chan_map().get(chan[1:])
			if not c: return
			for conn in self.bridge.cmd_chan_conns(c.name):
				if skip_self and conn is self: continue
				conn.send(f':{src} {msg_type} {chan} :{text}')
			if not notice: self.bridge.irc_msg(self, chan, text)
		else:
			conn = self.bridge.cmd_conn(target)
			if not conn:
				if not notice: self.send(401, target, ':No such nick/channel')
			else: conn.send(f':{src} {msg_type} {target} :{text}')

	def cmd_msg_synth(self, src, target, text, notice=False, direct=False):
		'''Synthetic PRIVMSG which avoids any self-reaction loops like notices
			Channel target must be prefixed by #. direct=True msg only goes to self.'''
		msg_type = 'PRIVMSG' if not notice else 'NOTICE'
		if direct: return self.send(f':{src} {msg_type} {target} :{text}')
		self.cmd_msg(src, target, text, notice=True, msg_type=msg_type)

	# XXX: more server info commands
	# def recv_cmd_admin(self):
	# def recv_cmd_connect(self):
	# def recv_cmd_time(self):
	# def recv_cmd_stats(self):
	# def recv_cmd_info(self):



class DiscordError(Exception): pass
class DiscordAbort(DiscordError): pass
class DiscordHTTPError(DiscordError): pass
class DiscordSessionError(Exception): pass


class Discord:

	def __init__(self, rdircd):
		self.bridge, self.loop, self.conf = rdircd, rdircd.loop, rdircd.conf
		self.log = get_logger('rdircd.discord.main')
		self._repr = ft.partial(str_repr, max_len=self.conf.debug_msg_cut)

	async def __aenter__(self):
		if not ( self.conf.get(f'auth_main_email')
				and self.conf.get(f'auth_main_password') ):
			self.log.error('Disabling discord due to missing access credentials')
			self.session = None
		else:
			s = self.session = DiscordSession(self, 'main')
			s.task = self.loop.create_task(s.run_async())
		self.flake_id = (int.from_bytes(os.urandom(2), 'big') & 0x3ff) << 12
		self.flake_n, self.msg_confirms = 0, dict()
		return self

	async def __aexit__(self, *err):
		if self.session: await task_cancel(self.session.task)

	def connect(self):
		if self.session: self.session.connect()
	def disconnect(self):
		if self.session: self.session.disconnect()

	def flake_parse(self, flake):
		if not flake: return None
		try: return (int(flake) >> 22)/1e3 + 1420070400
		except ValueError: return None
	def flake_build(self, ts):
		flake = self.flake_n | self.flake_id | int((ts - 1420070400) * 1e3) << 22
		self.flake_n = (self.flake_n + 1) % 0xfff
		return str(flake)

	@property
	def st(self):
		try: return self.session.st
		except KeyError: return adict()

	async def cmd_history(self, gg, cc, ts, lwm=70, hwm=90):
		if not self.session: return list()
		msg_list, flake = list(), self.flake_build(ts)
		while True:
			msg_batch = await self.session.req(
				f'channels/{cc.id}/messages',
				params=dict(after=flake, limit=hwm) )
			for m in map(adict, msg_batch or list()):
				line, tags = self.session.op_msg_parse(m, gg)
				# Note: parse_iso8601(m.timestamp) == flake_parse(m.id)
				msg_list.append(adict( nick=m.author.username,
					line=line.strip(), tags=tags, ts=self.flake_parse(m.id) ))
			if len(msg_list) < lwm: break
		return sorted(msg_list, key=op.itemgetter('ts'))

	def cmd_msg_recv(self, acc, cc, nick,
			line, tags=None, flake=None, nonce=None ):
		self.log.debug('MSG: {} {} :: {} :: {} {}', acc, cc.name, nick, line, tags)
		if acc != 'main': return
		if nonce and flake:
			fut = self.msg_confirms.pop(nonce, None)
			if fut: return fut.set_result(flake)
		self.bridge.discord_msg( cc.did,
			nick, line, tags, ts=self.flake_parse(flake) or time.time() )

	async def cmd_msg_send(self, cc, line):
		if not self.session: raise IRCBridgeSignal('no-discord-conn')
		try:
			nonce = self.flake_build(time.time())
			fut = self.msg_confirms[nonce] = asyncio.Future()
			res = await self.session.req(
				f'channels/{cc.id}/messages',
				m='post', json=dict(content=line, nonce=nonce) )
			try: flake_res = res['id']
			except: raise DiscordError(f'Invalid response: {res}')
			try:
				flake_gw = await asyncio.wait_for( fut,
					self.conf.discord_msg_confirm_timeout )
			except asyncio.TimeoutError:
				self.msg_confirms.pop(nonce, None)
				raise IRCBridgeSignal('msg-confirm-timed-out')
			if flake_gw != flake_res:
				self.log.warning( 'Same-nonce sent/received'
					' msg-id mismatch: {} != {}', flake_gw, flake_res )
			self.log.debug('Sending of msg {} confirmed: {}', flake_res, self._repr(line))
		except Exception as err:
			if isinstance(err, IRCBridgeSignal): raise
			err_str = err_fmt(err)
			self.log.exception('Failed sending discord msg: {}', err_str)
			raise IRCBridgeSignal(err_str)



class DiscordSession:

	api_ver = 6

	class c(enum.IntEnum):
		dispatch = 0
		heartbeat = 1
		identify = 2
		status_update = 3
		voice_state_update = 4
		resume = 6
		reconnect = 7
		request_guild_members = 8
		invalid_session = 9
		hello = 10
		heartbeat_ack = 11
		unknown_error = 4000
		unknown_opcode = 4001
		decode_error = 4002
		not_authenticated = 4003
		authentication_failed = 4004
		already_authenticated = 4005
		invalid_seq = 4007
		rate_limited = 4008
		session_timeout = 4009
		invalid_shard = 4010
		sharding_required = 4011
		oneshot = 10_000

	class c_chan_type(enum.IntEnum):
		text = 0
		private = 1
		voice = 2
		private_group = 3
		group = 4 # header for a group of channels

	class c_msg_type(enum.IntEnum):
		default = 0
		recipient_add = 1
		recipient_remove = 2
		call = 3
		channel_name_change = 4
		channel_icon_change = 5
		channel_pinned_message = 6
		guild_member_join = 7

	c_msg_tags = enum.Enum('c_msg_tags', 'user chan role all other')

	def __init__(self, discord, t):
		self.discord, self.loop, self.conf, self.t = discord, discord.loop, discord.conf, t
		self.api_url = self.conf.discord_api_url.format(api_ver=self.api_ver)
		self.log = get_logger(f'rdircd.discord.{self.t}')
		self.log_ws = get_logger(f'proto.ws.{self.t}')
		self.log_http = get_logger(f'proto.http.{self.t}')
		self.log_http_reqres = get_logger(f'proto.http.reqres')
		self._repr = ft.partial(str_repr, max_len=self.conf.debug_proto_cut)

	def get_auth(self, k, default=ValueError):
		try: return getattr(self.conf, f'auth_{self.t}_{k}')
		except AttributeError as err:
			if default is ValueError: raise
			return default

	async def __aenter__(self):
		if not (self.get_auth('email') and self.get_auth('password')):
			raise DiscordSessionError('Missing account auth credentials')
		self.ctx, self.tasks = contextlib.AsyncExitStack(), StacklessContext(self.log)
		self.http = await self.ctx.enter_async_context(aiohttp.ClientSession())
		self.ws_ctx = self.ws = self.ws_tasks = self.ws_handlers = None
		self.rate_limits, self.ws_closed = adict(), asyncio.Event()
		self.st = adict(guilds={1: adict(
			id=1, name='me', ts_joined=0, kh='me', chans=dict(), users=dict() )})
		self.st.me = self.st.guilds[1]
		self.auth_token = self.get_auth('token')
		return self

	async def __aexit__(self, *err):
		if self.ws_ctx: await self.ws_ctx.aclose()
		if self.ctx: await self.ctx.aclose()
		if self.tasks: await self.tasks.close()

	async def run(self):
		self.log.debug('Initializing discord session...')
		try: await asyncio.Future()
		except asyncio.CancelledError: pass
		self.log.debug('Finished')

	async def run_async(self):
		async with self: await self.run()

	def connect(self):
		# XXX: start reconnect logic/task, report back to irc control
		return self.tasks.add(self.ws_connect())
	def disconnect(self): return self.tasks.add(self.ws_close())

	def state(self, st):
		st_old, self.st.state = self.st.get('state', 'none'), st
		if st == st_old: return
		self.log_ws.debug( '--- state: {} -> {}',
			st_old, st, extra=('---', f'st {st_old} -> {st}') )
		self.log.info('State: {} -> {}', st_old, st)


	### Regular HTTP requests and OAuth2 stuff

	async def rate_limit_wrapper(self, route, req_func):
		# XXX: global limits currently only handled via http-429
		req_limit_defaults = 1, None
		while True:
			ts = time.time()
			req_limit, req_limit_ts = self.rate_limits.get(route) or req_limit_defaults
			if req_limit_ts and ts > req_limit_ts: req_limit = 1
			if req_limit <= 0 and req_limit_ts and req_limit_ts > ts:
				delay = req_limit_ts - ts
				self.log.debug('Rate-limiting request on route {!r}: delay={:,.1f}s', route, delay)
				await asyncio.sleep(delay + self.conf.discord_http_delay_padding)
			res = await req_func()
			req_limit_headers = list( res.headers.get(k)
				for k in ['X-RateLimit-Remaining', 'X-RateLimit-Reset'] )
			if any(req_limit_headers):
				warn, req_limit_vals = False, list(req_limit_defaults)
				for n, v in enumerate(req_limit_headers):
					try: req_limit_vals[n] = float(v)
					except ValueError as err: warn = False
				if warn:
					self.log.warning( 'Failed to parse rate-limit http'
						' header value(s), assuming default(s): {!r} / {!r}', *req_limit_headers )
				req_limit, req_limit_ts = self.rate_limits[route] = req_limit_vals
			if res.status == 429:
				m = await res.json()
				delay = m.get('retry_after')
				if delay:
					self.log.debug( 'Rate-limiting request on route'
							' {!r}: explicit-retry-after, delay={:,.1f}s, global={}, msg={!r}',
						route, delay, m.get('global'), m.get('message') )
					await asyncio.sleep(float(delay) / 1e3 + self.conf.discord_http_delay_padding)
					continue
				elif req_limit <= 0 and req_limit_ts and req_limit_ts > time.time(): continue
				else:
					raise DiscordSessionError(
						'Failed to get API rate-limiting retry delay for http-429 error' )
			break
		return res

	async def req_auth_token(self):
		if isinstance(self.auth_token, asyncio.Event): await self.auth_token
		elif not self.auth_token:
			self.auth_token = asyncio.Event()
			email, pw = (self.get_auth(k) for k in ['email', 'password'])
			res = await self.req( 'auth/login', m='post',
				auth=False, json=dict(email=email, password=pw) )
			if res.get('mfa'):
				raise DiscordSessionError( 'Multi-factor auth'
					' requirement detected, but is not supported by rdircd' )
			setattr(self.conf, f'auth_{self.t}_token', res['token'])
			self.conf.update_file_section(f'auth_{self.t}', 'token')
			self.auth_token.set()
			self.auth_token = self.get_auth('token')
		return self.auth_token

	async def req( self, url, m='get',
			route=None, auth=True, raw=False, **kws ):
		if not re.search(r'^https?:', url):
			url = urllib.parse.urljoin(self.api_url, url)
		if route is None: route = url
		kws.setdefault('headers', dict()).setdefault(
			'User-Agent', self.conf.discord_user_agent )
		for att in 'normal', 'token_refresh':
			if auth:
				token = await self.req_auth_token()
				kws.setdefault('headers', dict()).update(Authorization=token)
			req_func = ft.partial(self.http.request, m, url, **kws)
			self.log_http.debug(' >> {} {}', m, url, extra=(' >>', f'{m} {url}'))
			res = await self.rate_limit_wrapper(route, req_func)
			if not auth: break
			if res.status == 401:
				res.release()
				if att != 'normal': raise DiscordSessionError('Auth failed')
			break
		if res.status >= 400:
			body = await res.text()
			raise DiscordHTTPError(f'[{res.status}] {res.reason} - {body}')
		if self.log_http_reqres.isEnabledFor(logging.DEBUG):
			self.log_http_reqres.debug('', extra=('<< ', 'res :: headers start'))
			self.log_http_reqres.debug('', extra=( '<  ',
				f'  {res.status} {res.reason} HTTP/{res.version.major}.{res.version.minor}' ))
			for k, v in res.headers.items():
				self.log_http_reqres.debug('', extra=('<  ', f'  {k}: {v}'))
			self.log_http_reqres.debug('', extra=('<< ', 'res :: headers end'))
		if not raw:
			res_raw, res = res, await res.json()
			res_raw.release()
		res_repr = str(res)
		if '\n' in res_repr: res_repr = (res_repr.strip() + ' ').splitlines()[0]
		self.log_http.debug('<<  {}', self._repr(res_repr), extra=('<< ', res_repr))
		return res


	### Gateway Websocket wrappers

	async def ws_connect(self):
		if self.ws_ctx: return
		self.state('connecting.init')
		self.ws_ctx = ctx = contextlib.AsyncExitStack()
		self.ws_tasks, self.ws_handlers = StacklessContext(self.log), dict()
		ctx.push_async_callback(self.ws_close)
		self.ws_closed.clear()
		for cache in True, False:
			if cache:
				if not self.conf.discord_gateway: continue
				self.state('connecting.ws.cached')
			else:
				self.state('connecting.ws.get-url')
				self.conf.discord_gateway = (await self.req('gateway', auth=False))['url']
				self.conf.update_file_section('discord', 'gateway')
			parts = adict(urllib.parse.urlsplit(self.conf.discord_gateway)._asdict())
			query = urllib.parse.parse_qs(parts.query)
			query.update(v=str(self.api_ver), encoding='json')
			parts.query = urllib.parse.urlencode(query)
			ws_url = urllib.parse.urlunsplit(tuple(parts.values()))
			self.log_ws.debug('--- -conn- {}', ws_url, extra=('---', f'conn {ws_url}'))
			self.state('connecting.ws')
			try:
				self.ws = await ctx.enter_async_context(self.http.ws_connect( ws_url,
					headers={'User-Agent': self.conf.discord_user_agent},
					heartbeat=self.conf.discord_ws_heartbeat, timeout=self.conf.discord_ws_timeout ))
			except aiohttp.ClientError as err:
				err_str = err_fmt(err)
				self.log_ws.debug('--- -conn-fail- {}', err_str, extra=('---', f'conn-fail {err_str}'))
				self.state('connecting.ws.error')
				self.log.error('Gateway connection error: {}', err_str)
				if cache: continue # try fetching new gw url
			else: break
		else: self.ws = None
		if not self.ws: # XXX: more specific error/details, handle wrt reconnect
			self.state('connecting.ws.fail')
			self.ws_closed.set()
			raise DiscordSessionError('Failed to connect to discord')
		self.state('connected')
		self.ws_add_handler(self.c.dispatch, self.op_track_seq)
		self.ws_add_handler(self.c.reconnect, self.op_reconnect)
		self.ws_add_handler(self.c.hello, self.op_hello)
		self.ws_add_handler(self.c.invalid_session, self.op_invalid_session_retry)
		self.ws_tasks.add(self.ws_poller()).add_done_callback(self.ws_poller_done)

	_ws_handler = cs.namedtuple('ws_handler', 'op t func')
	def ws_add_handler(self, op=None, func=None, t=None, replace=False, remove=False):
		if replace or remove:
			for k, wsh in list(self.ws_handlers.items()):
				if wsh.op == op and wsh.t == t: del self.ws_handlers[k]
			if remove: return
		if not func: raise ValueError(func)
		wsh = self._ws_handler(op, t, func)
		self.ws_handlers[wsh] = wsh

	async def ws_poller(self):
		# {op=0**, s=**42, d={...}, t=**'GATEWAY_EVENT_NAME'}
		# {op=...[, d={...}]}
		async for msg in self.ws:
			msg_type = aiohttp.WSMsgType(msg.type).name.lower()
			msg_data = getattr(msg, 'data', '')
			self.log_ws.debug( '<<  {} {}', msg_type,
				self._repr(msg_data), extra=('<< ', f'{msg_type} {msg_data}') )
			if msg.type == aiohttp.WSMsgType.text:
				msg_data, hs_discard, handled = adict(json.loads(msg.data)), set(), False
				if self.conf.ws_dump_filter and self.conf.ws_dump_file:
					chk = self.conf.ws_dump_filter
					if ( chk.get('op') == msg_data.get('op')
							and chk.get('t') == msg_data.get('t') ):
						with open(self.conf.ws_dump_file, 'w') as dst: dst.write(msg.data)
				for k, h in list(self.ws_handlers.items()):
					if h.op is not None and msg_data.get('op') != h.op: continue
					if h.t is not None and (msg_data.get('t') or '').lower() != h.t: continue
					handled = True
					status = await await_wrap(h.func(msg_data))
					if status is self.c.oneshot: hs_discard.add(k)
				for k in hs_discard: self.ws_handlers.pop(k, None)
				if not handled:
					err, msg_repr = 'unhandled-text', self._repr(msg_data)
					self.log_ws.debug( 'xxx {} {}', err,
						msg_repr, extra=('xxx', f'{err} {msg_data}') )
					self.log.debug('Unhandled ws event: {}', msg_repr)
			elif msg.type == aiohttp.WSMsgType.closed: break
			elif msg.type == aiohttp.WSMsgType.error:
				self.log_ws.debug('err {}', msg, extra=('err', msg))
				self.log.error('ws protocol error, aborting: {}', msg)
				break
			else: self.log.warning('Unhandled ws msg type {}, ignoring: {}', msg.type, msg)

	def ws_poller_done(self, fut):
		err = fut.exception()
		if err:
			self.log.exception( 'Unhandled ws handler'
				' failure, aborting: {}', err_fmt(err), exc_info=err )
		self.tasks.add(self.ws_close())

	def ws_send(self, op, d):
		msg_data = json.dumps(dict(op=op, d=d))
		self.log_ws.debug( ' >> text {}',
			self._repr(msg_data), extra=(' >>', f'text {msg_data}') )
		self.tasks.add(self.ws.send_str(msg_data))

	async def ws_close(self):
		if self.ws_closed.is_set(): return
		self.log_ws.debug('--- -close-', extra=('---', 'close'))
		self.state('disconnected')
		if self.ws: await self.ws.close()
		self.ws_closed.set() # XXX: monitor for reconnect, close/wait ws_ctx there
		await self.ws_tasks.close()
		self.ws_ctx = self.ws = self.ws_tasks = self.ws_handlers = None


	### Gateway Websocket protocol
	# XXX: rate limits here?

	def op_log_warn(self, m):
		self.log.warning('Unhandled event: {}', m)

	def op_track_seq(self, m): self.st.seq = m.s
	def op_reconnect(self, m):
		self.log.info('Received reconnect event - closing connection')
		self.tasks.add(self.ws_close)

	async def op_hello(self, m):
		self.state('hello')
		interval = m.d.heartbeat_interval / 1e3
		self.log.debug('Heartbeat interval: {:,.2f}', interval)
		self.ws_tasks.add(self.op_heartbeat_task(interval))
		await self.op_hello_auth()
		return self.c.oneshot

	async def op_hello_auth(self):
		self.state('hello.auth.token')
		token = await self.req_auth_token()
		if not self.st.get('session_id'):
			self.state('hello.auth.identify')
			self.ws_add_handler(self.c.dispatch, t='ready', func=self.op_ready)
			self.ws_send(self.c.identify, dict(
				properties={'$os': 'linux', '$browser': 'rdircd', '$device': 'rdircd'},
				token=token, compress=False, large_threshold=250 ))
		else:
			self.state('hello.auth.resume')
			self.ws_add_handler(self.c.dispatch, t='resumed', func=self.op_ready)
			self.ws_send(self.c.resume, dict(
				token=token, session_id=self.st.session_id, seq=self.st.get('seq') ))

	async def op_heartbeat_task(self, interval):
		self.st.hb_ts_ack = hb_ts = self.loop.time() + interval
		self.ws_add_handler(self.c.heartbeat_ack, self.op_heartbeat_ack)
		while not self.ws_closed.is_set():
			self.ws_send(self.c.heartbeat, self.st.get('seq'))
			ts = self.loop.time()
			if self.st.hb_ts_ack < ts - interval*2:
				self.state('heartbeat.fail')
				self.log.error('Missing heartbeat ack, reconnecting')
				return await self.ws_close()
			while hb_ts <= ts: hb_ts += interval
			delay = hb_ts - ts
			await asyncio.sleep(delay)

	def op_heartbeat_ack(self, m):
		self.st.hb_ts_ack = self.loop.time()

	async def op_invalid_session_retry(self, m):
		self.log.info(
			'Session/auth rejected during handshake'
			' - updating auth token and retrying after delay' )
		# "expected to wait a random amount of time -
		#  - between 1 and 5 seconds - then send a fresh Opcode 2 Identify"
		self.state('session.error.delay')
		await asyncio.sleep(1 + random.random() * 4)
		self.auth_token = None
		self.ws_add_handler( self.c.invalid_session,
			self.op_invalid_session_fail, replace=True )
		self.state('session.error')
		await self.op_hello_auth()

	async def op_invalid_session_fail(self, m):
		self.log.info('Session/auth rejected unexpectedly - closing connection')
		self.state('session.fail')
		await self.ws_close()

	def op_ready(self, m):
		md = m.get('d')
		if md:
			self.st.update(
				session_id=md.session_id,
				user_id=md.user.id,
				user_name=md.user.username,
				user_n=md.user.discriminator )
			self.op_ev_guilds(md.get('guilds'), sync=True)
			self.op_ev_chans(self.st.me.id, md.get('private_channels'), sync=True)
		self.state('ready')
		self.ws_add_handler(self.c.dispatch, func=self.op_ev)
		self.ws_add_handler( self.c.invalid_session,
			self.op_invalid_session_fail, replace=True )
		return self.c.oneshot

	def op_ev(self, m):
		mt = (m.get('t') or '').lower()
		try: o, act = mt.rsplit('_', 1)
		except ValueError: o = act = None
		try: gid = m.d.guild_id
		except: gid = None
		if o == 'guild':
			if act in ['create', 'update']: return self.op_ev_guilds(guild=m.d)
			elif act == 'delete': return self.op_ev_delete(gid)
		elif o == 'channel':
			if act in ['create', 'update']: return self.op_ev_chans(gid, m.d)
			elif act == 'delete': return self.op_ev_delete(gid, chan=m.d.id)
		elif o == 'guild_member': return
			# if act in ['add', 'update']: return self.op_ev_users(gid, m.d.user)
			# elif act == 'delete': return self.op_ev_delete(gid, user=m.d.user.id)
		elif o == 'message':
			if act in ['create', 'update', 'delete']: return self.op_msg(m.d, act)
			elif act == 'delete_bulk': # can maybe shorten msg-spam here somehow
				for msg_id in m.d.ids: self.op_msg(adict(id=msg_id, **m.d), 'delete')
				return
		elif mt == 'typing_start': pass # no need for these
		# elif o == 'message_reaction':
		# elif o == 'relationship':
		# elif o == 'channel_pins':
		# elif o == 'presence':
		self.log.debug('Unhandled event: {}', self._repr(m))

	def op_ev_delete(self, gid=None, user=..., chan=...):
		gg = self.st.guilds.get(gid)
		if not gg: return
		if user is not ...: gg.users.pop(user, None)
		elif chan is not ...: gg.chans.pop(chan, None)
		else: self.st.guilds.pop(gid, None)

	def op_ev_guilds(self, guilds, sync=False):
		# XXX: parse emojis, read_state
		gs_new, gs_meta = {1: self.st.me}, list()
		for g in force_list(guilds):
			if g.id == self.st.me.id or g.name == self.st.me.name:
				self.log.error('Skipping guild due to id/name conflict with "me" guild: {}', g)
				continue
			gg = gs_new.setdefault( g.id,
				self.st.guilds.get(g.id, adict(id=g.id, chans=dict(), users=dict())) )
			ts_joined = g.get('joined_at') or 0
			if ts_joined: ts_joined = parse_iso8601(ts_joined)
			gg.update(name=g.name, ts_joined=ts_joined)
			gs_meta.append(
				(g.id, *(g.get(k) for k in 'members channels'.split())) )
		dict_update(self.st.guilds, gs_new, sync=sync)
		for gid, users, chans in gs_meta:
			# self.op_ev_users(gid, users, sync=True)
			self.op_ev_chans(gid, chans, sync=True)

	def op_ev_chans(self, gid, chans, sync=False):
		gg = self.st.guilds.get(gid)
		if not gg: return
		cs, ct = dict(), self.c_chan_type
		for c in force_list(chans):
			if c.type in [ct.voice, ct.group]: continue
			cc = cs.setdefault(c.id, gg.chans.get(c.id, adict()))
			name, topic = c.get('name'), c.get('topic')
			if c.type in [ct.private, ct.private_group]:
				dict_update( cc.setdefault('users', dict()),
					( (u.id, adict(name=u.username))
						for u in (c.get('recipients') or list()) ), sync=True )
				user_names = list(u.name for u in cc.users.values())
				name = self.op_ev_chans_priv_name(user_names)
				if not topic: topic = 'private chat - ' + ', '.join(user_names)
			cc.update(
				id=c.id, gid=gg.id, did=f'#{gg.id}-{c.id}', name=name, t=ct(c.get('type', 0)),
				pos=c.get('position', -1)+1, topic=topic, nsfw=c.get('nsfw'),
				last_msg=c.get('last_message_id'), last_pin=c.get('last_pin_timestamp') )
		dict_update(gg.chans, cs, sync=sync)

	def op_ev_chans_priv_name(self, user_names, max_len=32):
		n = max_len
		while True:
			name = '+'.join(sorted(name.replace('+', '')[:n] for name in user_names))
			if n <= 1 or len(name) <= max_len: return name[:max_len]
			n -= 1

	# XXX: request userlist and maintain nicks[username, discriminator, server] mapping
	# def op_ev_users(self, gid, users, sync=False):
	# 	dict_update(gg.users, ((u.user.id, adict(
	# 		id=u.user.id, name=u.user.username,
	# 		deaf=u.get('deaf'), mute=u.get('mute') )) for u in force_list(users)), sync=sync)

	def op_msg(self, m, act):
		cc, gg = None, self.st.guilds.get(m.get('guild_id', 1))
		if gg: cc = gg.chans.get(m.channel_id)
		if not cc:
			return self.log.warning( 'Dropped msg event with unknown guild/channel'
				' id: msg_id={} guild_id={} channel_id={}', m.guild_id, m.id, m.channel_id )
		if act == 'delete':
			msg_ts = ts_iso8601(self.discord.flake_parse(m.id), human=True)
			return self.discord.cmd_msg_recv( self.t, cc,
				None, f'--- message was deleted: {msg_ts} [{m.id}]', flake=m.id )
		author = m.get('author')
		if not author:
			if act == 'update' and m.get('embeds'): pass # XXX: description for msg embeds
			else: self.log.warning('Unhandled empty msg type: {} [{}]', self._repr(m), act)
			return
		line, tags = self.op_msg_parse(m, gg)
		if not line: return # "m.type = joins/parts" can be used to track names here
		if act == 'update': line = f'{self.conf.irc_prefix_edit}{line}'
		self.discord.cmd_msg_recv( self.t, cc,
			author.username, line.strip(), tags, flake=m.id, nonce=m.get('nonce') )

	def op_msg_parse(self, m, gg):
		line = (m.get('content') or '').strip()
		line, tags = self.op_msg_parse_tags(line, m.get('mentions'), gg.chans.values())
		for att in m.get('attachments') or list():
			url = att.get('url')
			if not url:
				self.log.warning('Unhandled msg attachment type: {}', self._repr(att))
				continue
			line += f'\n{self.conf.irc_prefix_attachment}{url}'
		if not line:
			if m.get('type') == self.c_msg_type.guild_member_join: pass
			else: self.log.warning('Unhandled empty msg type: {}', self._repr(m))
		return line, tags

	def op_msg_parse_tags(self, line, users, chans):
		# XXX: mentions for roles and @everyone
		users = dict((m.id, m.username) for m in force_list(users))
		chans = dict((c.id, c.did) for c in force_list(chans))
		tags, mt = dict(), self.c_msg_tags
		for m in re.finditer(r'<([@#])(\d+)>', line): # XXX: check docs on these
			k_src, t, k = m.group(0), m.group(1), m.group(2)
			if t == '@': v = mt.user, users.get(k, f'@{k}')
			elif t == '#': v = mt.chan, chans.get(k, f'#{k}')
			else: v = mt.other, f'{t}{k}'
			tags[k_src] = v
		return line, tags

	# Not handled:
	#
	# - After READY: op=0 t=SESSIONS_REPLACE s=2
	#   d=[{ status=online, session_id=..., game=null,
	#     client_info={version=0, os=other, client=web}, activities=[] }]



class RDIRCD:

	class c:
		chan_control = 'control'
		chan_debug = 'debug'

	def __init__(self, loop, conf):
		self.loop, self.conf = loop, conf
		self.log = get_logger('rdircd.bridge')
		self._repr = ft.partial(str_repr, max_len=self.conf.debug_msg_cut)

	async def __aenter__(self):
		self.server_ver = self.conf.version
		self.server_ts = dt.datetime.utcnow()
		self.server_host = os.uname().nodename
		self.irc_conns, self.irc_conns_max = dict(), 0
		self.irc_auth_tbf = token_bucket(self.conf.irc_auth_tbf)
		self.nick_sys, self.chans_sys = 'core', {
			self.c.chan_control: 'rdircd: control channel, type "help" for more info',
			self.c.chan_debug: 'rdircd: debug logging channel, type "help" for more info' }
		self.tasks = StacklessContext(self.log)
		self.cache = adict(uid=dict(), d2i=dict(), i2d=dict())
		self.uid_len, self.uid_seed = (self.conf.get(f'irc_uid_{k}') for k in ['len', 'seed'])
		if not self.uid_seed:
			for k in '/etc/machine-id', '/var/lib/dbus/machine-id':
				try: self.uid_seed = str_hash(pl.Path(k).read_text().strip())
				except OSError: continue
			else: self.uid_seed = f'rdircd.{self.server_host}'
		boot_id = pl.Path('/proc/sys/kernel/random/boot_id').read_text().strip()
		self.uid_start = '.'.join( str_hash(v, c)
			for c, v in zip([3, 3, 6], [self.uid_seed, boot_id, os.urandom(6)]) )
		self.irc_msg_queue = asyncio.Queue()
		self.cmd_delay(self.irc_msg_queue_proc)
		return self

	async def __aexit__(self, *err):
		if self.irc_msg_queue: self.irc_msg_queue.put_nowait(StopIteration)
		if self.tasks: await self.tasks.close()

	def uid(self, k, v=None, kh=None, hash_len=None):
		if v is None: return self.cache.uid.get(k, (None, None))
		k = k, v
		if k not in self.cache.uid:
			if kh is None:
				kh = str_hash( '\0'.join(map(str, k)),
					hash_len or self.uid_len, self.uid_seed )
			if kh in self.cache.uid:
				# Hash collisions should not happen here - raise uid_len if they do
				raise ValueError(k, kh, self.cache.uid[kh])
			self.cache.uid[k], self.cache.uid[kh] = kh, k
		return self.cache.uid[k]

	async def run(self):
		ircd = await self.loop.create_server(
			IRCProtocol.factory_for_bridge(self),
			self.conf.irc_host, self.conf.irc_port,
			family=self.conf.irc_host_af, start_serving=False )
		self.log.debug('Initializing discord...')
		try:
			async with Discord(self) as discord:
				self.discord = discord
				self.log.debug('Starting ircd...')
				ircd_task = self.tasks.add(ircd.serve_forever())
				if self.conf.discord_auto_connect:
					self.log.debug('Auto-connecting discord...')
					self.loop.call_soon(discord.connect)
				await ircd_task
		except DiscordAbort as err:
			self.log.error('Discord init failure - {}', err_fmt(err))
		self.log.debug('Finished')

	async def run_async(self):
		async with self: await self.run()


	def irc_conn_new(self, irc):
		self.irc_conns[id(irc)] = irc
		self.irc_conns_max = max(self.irc_conns_max, len(self.irc_conns))
	def irc_conn_lost(self, irc): self.irc_conns.pop(id(irc), None)
	def irc_conn_stats(self):
		stats = adict(
			servers=len(self.discord.st.get('guilds', dict())) or 1,
			chans=len(self.cmd_chan_map()),
			total=0, total_max=self.irc_conns_max, unknown=0, auth=0, op=0 )
		for conn in self.irc_conns.values():
			stats.total += 1
			if conn.st.auth: stats.auth += 1
			else: stats.unknown += 1
		return stats
	def irc_conn_names(self):
		for conn in self.irc_conns.values():
			if conn.st.auth: yield conn.st.nick

	def irc_name(self, name):
		# Must be deterministic but not create collisions by stripping too much
		if name not in self.cache.d2i:
			name_irc, sub_chars = '', '°×·„∂'
			name_clean = re.sub(rf'[{sub_chars}]', '', name)
			if name_clean != name: name = name_clean + '×' + self.uid('name', name)
			for n, c in enumerate(name):
				if ord(c) < 32: name_irc += f'°{ord(c):02d}'
				elif c == ' ': name_irc += '·'
				elif c == ',': name_irc += '„'
				elif c == ':': name_irc += '⋮'
				elif c == '@': name_irc += '∂'
				elif c == '+': name_irc += '×'
				else: name_irc += c
			self.cache.d2i[name], self.cache.i2d[name_irc] = name_irc, name
		return self.cache.d2i[name]

	def irc_chan_info(self, name):
		if '.' not in name: return
		gid, name = name.split('.', 1)
		(t, gid), chan_name = self.uid(gid), self.cache.i2d.get(name)
		if t != 'guild': return
		gg = self.discord.st.get('guilds', dict()).get(gid)
		if not gg: return
		for cc in gg.chans.values():
			if cc.name == chan_name: break
		else: cc = None
		return adict(gg=gg, cc=cc)

	async def irc_topic_cmd(self, conn, chan, line=''):
		name, notice_cmd = conn.chan_name(chan), ft.partial(
			conn.cmd_msg_synth, self.nick_sys, chan, notice=True, direct=True )
		if not line.strip():
			return notice_cmd('\n'.join([ '--- Topic-commands:',
				'  set {topic...} - set topic, as usual irc /topic command would do.',
				'  log [state] - replay history since "state" point (default: last rdircd stop).',
				'    "state" value can be either a number, state-id, or iso8601 timestamp.',
				'    Where number indicates last Nth state recorded in the config (0 - current).',
				'    E.g. "log 1" (same as just "log") will replay messages in the channel,',
				'      starting from last rdircd shutdown time, recorded under [state] in the ini.',
				'  log list - list recorded state ids/timestamps, most recent one last.', '---' ]) )
		cmd = line.split(None, 1)
		try:
			if cmd[0] == 'set':
				raise IRCBridgeSignal('Changing topic is not implemented')
			elif cmd[0] == 'log':
				state = ('1' if len(cmd) == 1 else cmd[1]) if len(cmd) <= 2 else None
				state_list = sorted((v,k) for k,v in self.conf.state.items())
				if state == 'list':
					if not state_list: notice_cmd('No state timestamps recorded yet.')
					else:
						notice_cmd('Recorded state timestamps:')
						for n, (v, k) in enumerate(state_list):
							n = len(state_list) - n - 1
							notice_cmd(f'  [{n}] {k} = {ts_iso8601(v)}')
					return
				ts = None
				if state.isdigit():
					n = -1 - int(state)
					if not self.conf.state_get(self.uid_start): n += 1
					if not n: return
					try: ts, k = state_list[n]
					except IndexError: raise IRCBridgeSignal(f'No state with index {state}')
				elif state in self.conf.state:
					try: ts = self.conf.state[state]
					except KeyError: raise IRCBridgeSignal(f'No state {state!r}')
				else:
					try: ts = parse_iso8601(state)
					except ValueError: pass
				if ts:
					info = self.irc_chan_info(name)
					if not (info and info.cc): raise IRCBridgeSignal(f'Not a discord channel: {chan}')
					notice_cmd(f'--- Replaying new messages since {ts_iso8601(ts)}')
					msg_list = await self.discord.cmd_history(info.gg, info.cc, ts)
					if not msg_list: return notice_cmd('--- no new messages')
					for m in msg_list:
						line = f'[{ts_iso8601(m.ts, human=True)}] {m.line}'
						self.discord_msg(info.cc.did, m.nick, line, m.tags, conn=conn)
					return notice_cmd(f'--- end of replay [{len(msg_list)}]')
				raise IRCBridgeSignal(f'Invalid log-cmd parameters: {line}')
			else: raise IRCBridgeSignal(f'Unrecognized channel-topic cmd: {line}')
		except IRCBridgeSignal as err:
			notice_cmd(f'topic-cmd-error: {err}')
			raise

	def irc_msg(self, conn, chan, line):
		name = conn.chan_name(chan)
		if name in self.chans_sys:
			return self.cmd_chan_sys(name, conn, chan, line)
		# XXX: add mention/channel tags to messages
		if not line.strip(): return
		if not self.irc_msg_queue:
			conn.cmd_msg_synth( self.nick_sys, chan,
				f'ERR {{irc-msg-queue-failed}}: {line}', notice=True, direct=True )
		else: self.irc_msg_queue.put_nowait(
			adict(conn=conn, chan=chan, name=name, line=line) )

	async def irc_msg_queue_proc(self):
		try:
			while True:
				m = await self.irc_msg_queue.get()
				if m is StopIteration: break
				info = self.irc_chan_info(m.name)
				try:
					if not (info and info.cc): raise IRCBridgeSignal('no-matching-chan')
					await self.discord.cmd_msg_send(info.cc, m.line)
				except IRCBridgeSignal as err:
					m.conn.cmd_msg_synth( self.nick_sys, m.chan,
						f'ERR {{{err}}}: {self._repr(m.line)}', notice=True, direct=True )
					while True: # flush queue to ensure ordering
						try: m = self.irc_msg_queue.get_nowait()
						except asyncio.QueueEmpty: break
						if m is StopIteration: break
						m.conn.cmd_msg_synth( self.nick_sys, m.chan,
							f'ERR-flush {{{err}}}: {self._repr(m.line)}', notice=True, direct=True )
					if m is StopIteration: break
		finally: self.irc_msg_queue = None


	def cmd_delay(self, delay, func=None):
		if func is None: delay, func = 0, delay
		if delay and not isinstance(delay, (int, float)):
			if delay == 'irc_auth': delay = next(self.irc_auth_tbf)
			else: raise ValueError(delay)
		if delay: self.tasks.add(asyncio.sleep(delay), func)
		else: self.tasks.add(await_wrap(func()))

	def cmd_conn(self, name=None):
		for conn in self.irc_conns.values():
			if not name or name == conn.st.nick: return conn

	@iter_gather(list)
	def cmd_chan_conns(self, name):
		for conn in self.irc_conns.values():
			if name in conn.st.chans: yield conn

	@iter_gather(sorted, cache=True)
	def cmd_chan_names_discord(self, cache_track, name):
		info = self.irc_chan_info(name)
		if not info: return
		cache_track(info.gg, 'users')
		names = set(self.irc_name(u.name) for u in info.gg.users.values())
		if info.cc and 'users' in info.cc:
			names.update(self.irc_name(u.name) for u in info.cc.users.values())
		yield from names.difference(self.irc_conn_names())

	@iter_gather(sorted)
	def cmd_chan_names(self, name):
		for conn in self.cmd_chan_conns(name): yield conn.st.nick
		yield from self.cmd_chan_names_discord(name)

	@iter_gather(adict, cache=True)
	def cmd_chan_map(self, cache_track):
		for name, topic in self.chans_sys.items():
			yield (name, adict( name=name, topic=topic,
				names=self.cmd_chan_names(name),
				ts_created=self.server_ts.timestamp() ))
		ct = DiscordSession.c_chan_type
		for gg in sorted(
				self.discord.st.get('guilds', dict()).values(),
				key=op.itemgetter('ts_joined') ):
			cache_track(gg, 'name chans users ts_joined')
			gid_pre = self.uid('guild', gg.id, kh=gg.get('kh'))
			for cc in sorted(
					gg.chans.values(),
					key=lambda cc: (cc.get('pos') or 999, cc.name) ):
				cache_track(cc, 'name topic pos nsfw')
				name = f'{gid_pre}.{self.irc_name(cc.name)}'
				tags = '[NSFW] ' if cc.nsfw else ''
				topic = ' // '.join(filter(None, map(str.strip, (cc.topic or '').splitlines())))
				topic = f'{gg.name.strip()}: {tags}{topic}'.strip()
				self.cache.d2i[cc.did] = name
				yield (name, adict(
					name=name, topic=topic, did=cc.did,
					ts_created=gg.ts_joined, names=self.cmd_chan_names(name) ))


	def cmd_chan_sys(self, name, conn, chan, line):
		getattr(self, f'cmd_chan_sys_{name}')(conn, chan, line)

	def cmd_chan_sys_control(self, conn, chan, line):
		line = line.strip().lower().split()
		if not line: return
		cmd, send = line[0],\
			ft.partial(conn.cmd_msg_synth, self.nick_sys, chan)
		if cmd in ['h', 'help']:
			self.cmd_chan_sys_control_status(send)
			send('\n'.join([
				'Commands:',
				'  status - (alias: st) show whether discord is connected and working',
				'  connect - (alias: on) connect/login to discord',
				'  disconnect - (alias: off) disconnect from discord',
				'Only immediate response to sent commands is logged here - no noise over time.' ]))
		elif cmd in ['status', 'st']: self.cmd_chan_sys_control_status(send)
		elif cmd in ['connect', 'on']:
			send('discord: connection started')
			self.discord.connect()
		elif cmd in ['disconnect', 'off']:
			send('discord: disconnecting')
			self.discord.disconnect()

	def cmd_chan_sys_control_status(self, send):
		sess_state = self.discord.st.get('state', 'none')
		counts = self.conf._debug_counts
		counts = ' '.join( '{}={:,d}'.format(k, counts[k]) for n, k in
			sorted(((n, k.lower()) for n, k in logging._levelToName.items()), reverse=True)
			if counts[k] > 0 )
		send('\n'.join([ 'Status:',
			f'  discord-state: {sess_state}',
			f'  log-msg-counts: {counts}' ]))

	def cmd_chan_sys_debug(self, conn, chan, line):
		line_src, line = line, line.strip().lower().split()
		if not line: return
		send = ft.partial(conn.cmd_msg_synth, self.nick_sys, chan)
		if line[0] in ['h', 'help']:
			level = proto_log_info = '???'
			if self.conf._debug_chan:
				level = logging.getLevelName(self.conf._debug_chan.level).lower()
			if self.conf._debug_proto:
				proto_log_info = logging.getLevelName(self.conf._debug_proto.level).lower()
				proto_log_info = ( 'disabled' if proto_log_info == 'warning'
					else f'enabled, file={self.conf._debug_proto.baseFilename}' )
			return send('\n'.join(f'-- {line}' for line in [
				'This channel is for logging output, with level=info by default,',
				' unless --debug is specified on command line, or [debug] verbose=yes in ini.',
				f'Status:',
				f'  logging level: {level}',
				f'   protocol log: {proto_log_info}',
				'Recognized commands here:',
				'  level info - (alias: i) set level=info (default) logging in this channel',
				'  level debug - (alias: d) enable level=debug logging in this channel (verbose)',
				'  level warning - (alias: w) only dump warnings and errors here',
				'  proto {file} - enable irc/discord procool logging to specified file',
				'  proto off - disable irc/discord procool logging' ]))
		if len(line) == 1:
			with contextlib.suppress(KeyError):
				line = dict(i='level info', d='level debug', w='level warning')[line[0]].split()
		cmd, arg = line[0], line[-1]
		if cmd == 'level' and len(line) == 2:
			level = getattr(logging, arg.upper(), None)
			if level is not None and self.conf._debug_chan:
				self.conf._debug_chan.setLevel(level)
			else: arg = 'unavailable'
			send(f'-- logging level: {arg}')
		elif cmd == 'proto':
			if arg == 'off':
				if self.conf._debug_proto:
					self.conf._debug_proto.setLevel(logging.WARNING)
				else: arg = 'unavailable'
				send(f'-- protocol log: {arg}')
			elif len(line) >= 2:
				path = line_src.strip().split(None, 1)[-1] # preserve spaces and case
				if self.conf._debug_proto:
					self.conf._debug_proto.set_file(path)
					self.conf._debug_proto.setLevel(logging.DEBUG)
					arg = f'file={path}'
				else: arg = 'unavailable'
				send(f'-- protocol log: {arg}')

	def cmd_log(self, line):
		conn = self.cmd_conn()
		if not conn: return
		conn.cmd_msg_synth( self.nick_sys,
			conn.chan_spec(self.c.chan_debug), line )


	def discord_msg(self, did, nick, line, tags=None, ts=None, conn=None):
		if ts: self.conf.state_set(self.uid_start, ts)
		name = self.cache.d2i.get(did)
		if not name: return
		conn_list = [conn] if conn else self.cmd_chan_conns(name)
		if not conn_list: return
		elif not conn: conn = conn_list[0]
		if tags:
			mt = DiscordSession.c_msg_tags
			for k, (tt, v) in tags.items():
				if tt == mt.user: v = '@' + self.irc_name(v)
				elif tt == mt.chan: v = conn.chan_spec(self.cache.d2i.get(v, v))
				line = line.replace(k, v)
		if nick: nick = self.irc_name(nick)
		for conn in conn_list:
			conn.cmd_msg_synth( nick or self.nick_sys,
				conn.chan_spec(name), line, notice=not nick, direct=True )



class RDIRCDConfig:

	version = '1.42' # git-version: py-str

	irc_host = '127.0.0.1'
	irc_port = 6667
	irc_password = ''
	irc_host_af = 0
	irc_auth_tbf = '30:8'
	irc_uid_len = 4 # can be increased to fix conflicts
	irc_uid_seed = ''
	irc_prefix_edit = '[edit] '
	irc_prefix_attachment = '[att] '

	discord_auto_connect = True
	discord_api_url = 'https://discordapp.com/api/v{api_ver}/'
	discord_msg_confirm_timeout = 10.0
	discord_ws_timeout = 20.0
	discord_ws_heartbeat = 15.0
	discord_user_agent = ( f'rdircd/{version}'
		f' (reliable-discord-irc-client) aiohttp/{aiohttp.__version__}' )
	discord_http_delay_padding = 10.0 # added to retry_after
	discord_gateway = ''

	auth_main_email = ''
	auth_main_password = ''
	auth_main_token = ''

	debug_verbose = False
	debug_msg_cut = 50
	debug_proto_cut = 90
	debug_proto_log_shared = True
	debug_proto_log_file = ''
	debug_proto_log_file_size = int(1.5e6)
	debug_proto_log_file_count = 9
	debug_log_file = ''
	debug_log_file_size = int(1.5e6)
	debug_log_file_count = 9
	_debug_chan = _debug_proto = _debug_counts = None

	ws_dump_filter = None
	ws_dump_file = 'dump.json'
	# ws_dump_filter = adict(op=0, t='READY')

	state_tracked, state = True, None
	_state_section = _state_offsets = _state_file = _state_file_ts = None

	_conf_path = '~/.rdircd.ini'
	_conf_sections = 'irc', 'discord', 'auth_main', 'debug'

	def __init__(self):
		self.state = dict()
		self.log = get_logger('rdircd.state')

	def __repr__(self): return repr(vars(self))
	def get(self, *k): return getattr(self, '_'.join(k))
	def set(self, k, v): setattr(self, k, v)

	def read(self, func, section, k, conf_k=None):
		if not conf_k: conf_k = f'{section}_{k}'.replace('-', '_')
		for k in k, k.replace('-', '_'), k.replace('_', '-'):
			try:
				self.set(conf_k, func(section, k))
				return True
			except configparser.NoSectionError: pass
			except configparser.NoOptionError: pass

	def pprint(self, title=None, empty_vals=False):
		cat, chk = None, re.compile(
			'^({})_(.*)$'.format('|'.join(map(re.escape, self._conf_sections))) )
		if title: print(f';; {title}')
		for k in sorted(dir(self)):
			m = chk.search(k)
			if not m: continue
			v = self.get(k)
			if not empty_vals and not v: continue
			cat_chk = m.group(1).replace('_', '-')
			if cat_chk != cat:
				cat = cat_chk
				print(f'\n[{cat}]')
			if isinstance(v, bool): v = ['no', 'yes'][v]
			k = m.group(2).replace('_', '-')
			print(f'{k} = {v}')

	def read_from_file(self, *conf_paths):
		conf_file = configparser.ConfigParser(allow_no_value=True)
		conf_file.optionxform = lambda k: k
		conf_file.read(conf_paths)
		self._conf_path = conf_paths[-1]
		for k in self._conf_sections:
			self.update_from_file_section(conf_file, section=k, prefix=f'{k}_')
		self.read(conf_file.getboolean, 'state', 'tracked')
		self._state_section = conf_file.has_section('state')
		if self.state_tracked and self._state_section:
			for k, v in conf_file['state'].items():
				if k == 'tracked': continue
				self.state[k] = parse_iso8601(v)

	def update_from_file_section(self, config, section='default', prefix=None):
		section = section.replace('_', '-')
		for k in dir(self):
			if prefix:
				if not k.startswith(prefix): continue
				conf_k, k = k, k[len(prefix):]
			elif k.startswith('_'): continue
			else: conf_k = k
			v = getattr(self, conf_k)
			if isinstance(v, str): get_val = lambda *a: str(config.get(*a, raw=True))
			elif isinstance(v, bool): get_val = config.getboolean
			elif isinstance(v, int): get_val = lambda *a: int(re.sub(r'[ _]', '', config.get(*a)))
			elif isinstance(v, float): get_val = lambda *a: float(config.get(*a))
			else: continue # values with other types cannot be specified in config
			self.read(get_val, section, k, conf_k)

	def update_file_section(self, section, keys=None, path=None):
		section = section.replace('_', '-')
		if not path: path = self._conf_path
		if isinstance(path, str): path = pl.Path(path)
		sec_re, sec_k = re.compile(r'(?i)^\[\s*(\S+)\s*\]$'), str_norm(section)
		sec_prefix = section.lower().replace('-', '_') + '_'
		if not keys: keys = list(k for k in vars(self).keys() if k.startswith(sec_prefix))
		if isinstance(keys, str): keys = keys.split()
		if isinstance(keys, dict): keys = list(keys.items())
		for n, k in enumerate(keys):
			if isinstance(k, tuple): k, v = k
			else: v = ...
			k = k.replace('_', '-')
			if not k.startswith(sec_prefix): k = sec_prefix + k
			if v is ...: v = self.get(k)
			k = k[len(sec_prefix):]
			if isinstance(v, bool): v = ['no', 'yes'][v]
			keys[n] = k, v, re.compile(r'(?i)^' + k.replace('-', '[-_]') + r'\s*=')
		keys = dict((k, (v, rx)) for k, v, rx in keys)
		with path.open() as src, safe_replacement(path) as dst:
			lines, sec, sec_parse = list(), list(), False
			for n, line in enumerate(src):
				m, line = sec_re.search(line.strip()), line.rstrip()
				if m:
					k = str_norm(m.group(1))
					if k == sec_k:
						sec_parse = True
						if sec: line = '' # drop duplicate headers
					if k != sec_k: sec_parse = False
				if sec_parse: sec.append(line)
				else: lines.append(line)
			while sec and not sec[-1]: sec.pop()
			if not sec: sec.append(f'[{section}]')
			if lines and lines[-1]: lines.append('')
			for line in lines: dst.write(f'{line}\n')
			for n, line in enumerate(sec):
				for k, (v, rx) in keys.items():
					if not rx.search(line): continue
					if v is None: line = None
					else: line, keys[k] = f'{k} = {v}', (None, rx)
				if line is not None: dst.write(f'{line}\n')
			for k, (v, rx) in keys.items():
				if v is None: continue
				dst.write(f'{k} = {v}\n')
		self._state_source_flush()

	### Timestamps in [state] section are updated in-place,
	###  overwriting short timestamp values without tmp files.
	### File should be safe to edit manually regardless, due to ctime checks.

	def _state_source_flush(self):
		self._state_file = self._state_offsets = None

	def _state_source_get(self):
		if self._state_file and self._state_file_ts:
			try: ts = os.stat(self._state_file.name).st_ctime
			except OSError: ts = None
			if ts != self._state_file_ts: self._state_source_flush()
		if not self._state_file: self._state_file = open(self._conf_path, 'rb+')
		if self._state_offsets is None: self._state_offsets = self._state_offsets_read()
		return self._state_file, self._state_offsets

	def _state_offsets_read(self, section='state'):
		section, src = section.replace('_', '-'), self._state_file
		sec_re, sec_k = re.compile(r'(?i)^\[\s*(\S+)\s*\]$'), str_norm(section)
		src.seek(0)
		offsets, parse = dict(), False
		val_re = re.compile(b'^\s*([\w\d]\S+)\s*=\s*(\S+)\s*$')
		for line in iter(src.readline, b''):
			m = sec_re.search(line.decode().strip())
			if m:
				k = str_norm(m.group(1))
				if k == sec_k: parse = True
				else: parse = False
				continue
			if parse:
				m = val_re.search(line)
				if not m: continue
				k, v = m.group(1), m.group(2)
				pos = src.tell() - len(line) + m.start(2)
				offsets[k.decode()] = pos
				# src.seek(pos)
				# v_chk = src.read(len(v))
				# assert v_chk == v, [pos, v_chk, v]
				# src.readline()
		return offsets

	def state_get(self, k, t='last-msg'): return self.state.get(f'{t}.{k}')

	def state_set(self, k, ts, t='last-msg', sync=False):
		if not self.state_tracked: return
		if not self._state_section: self.update_file_section('state', 'tracked')
		k, v = f'{t}.{k}', ts_iso8601(ts)
		if k not in self.state:
			self.update_file_section('state', {k: v})
			self.state[k] = ts
			return self.state_cleanup()
		if self.state[k] > ts:
			self.log.warning( 'State timestamp'
				' jumped backwards: {} -> {}', self.state[k], ts )
		src, offsets = self._state_source_get()
		n, v = offsets[k], v.encode()
		src.seek(n)
		parse_iso8601(src.read(len(v)).decode(), validate=True)
		src.seek(n)
		src.write(v)
		src.flush()
		if sync: os.fdatasync(src.fileno())
		self.state[k], self._state_file_ts = ts, os.fstat(src.fileno()).st_ctime

	def state_cleanup(self, keep_max=10):
		keys = sorted((v,k) for k,v in self.state.items())
		if len(keys) <= keep_max: return
		src, offsets = self._state_source_get()
		offsets = sorted( ((offsets[k], k) for v,k in
			keys[:len(keys) - keep_max]), reverse=True )
		with src, safe_replacement(src.name, 'wb') as dst:
			src.seek(0)
			for line in iter(src.readline, b''):
				if offsets and offsets[-1][0] < src.tell():
					n, k = offsets.pop()
					del self.state[k]
					continue
				dst.write(line)
		self._state_source_flush()



def main(args=None, conf=None):
	if not conf: conf = RDIRCDConfig()

	import argparse, textwrap
	dedent = lambda text: (textwrap.dedent(text).strip('\n') + '\n').replace('\t', '  ')
	text_fill = lambda s,w=100,ind='\t',ind_next=None,**k: textwrap.fill(
		s, w, initial_indent=ind, subsequent_indent=ind if ind_next is None else ind_next, **k )
	class SmartHelpFormatter(argparse.HelpFormatter):
		def __init__(self, *args, **kws):
			return super().__init__(*args, **kws, width=100)
		def _fill_text(self, text, width, indent):
			if '\n' not in text: return super()._fill_text(text, width, indent)
			return ''.join( indent + line
				for line in text.replace('\t', '  ').splitlines(keepends=True) )
		def _split_lines(self, text, width):
			return super()._split_lines(text, width)\
				if '\n' not in text else dedent(text).splitlines()

	parser = argparse.ArgumentParser(
		formatter_class=SmartHelpFormatter,
		description='Reliable personal discord-client to irc-server translation daemon.')

	group = parser.add_argument_group('Configuration file(s)')
	group.add_argument('-c', '--conf',
		metavar='file', action='append',
		help=f'''
			Path to configuration file to use.
			It will get updated with OAuth2 credentials ([auth] section)
				and some state info ([state] section), so has to be writable.
			Default: {conf._conf_path}''')
	group.add_argument('--conf-dump', action='store_true',
		help='Print all configuration settings, which will be used with'
			' currently detected (and/or specified) configuration file(s), and exit.')
	group.add_argument('--conf-dump-defaults', action='store_true',
		help='Print all default settings, which would be used'
			' if no configuration file(s) were overriding these, and exit.')
	group.add_argument('--conf-dump-state', action='store_true',
		help='Print "state" section from the config file,'
			' with keys corresponding to app startups and iso8601'
			' time values of last received message for that run.')

	group = parser.add_argument_group('Interfaces')
	group.add_argument('-i', '--irc-bind', metavar='host(:port)',
		help=f'''
			Address/host (to be resolved via gai) and port to bind IRC server to.
			When specifying port after raw IPv6 address,
				enclose the latter in [], for example - [::]:6667.
			Default: {conf.irc_host}:{conf.irc_port} or whatever is in --conf file.''')

	group = parser.add_argument_group('Logging and debug opts')
	group.add_argument('-d', '--debug',
		action='store_true', help='Verbose operation mode.')
	group.add_argument('-t', '--proto-cut', type=int, metavar='n',
		help='Truncate long strings in protocol dumps to specified length.'
			' Set to <=0 to disable truncation (default).')
	group.add_argument('-p', '--proto-log', metavar='file',
		help='''
			File to dump full non-truncated protocol logs to.
			Max file size and rotation options can be configured via --conf file.''')
	group.add_argument('-l', '--debug-log', metavar='file',
		help='''
			Separate file for debug-level logging, regardless of levels set elsewhere.
			Max file size and rotation options can be configured via --conf file.''')

	opts = parser.parse_args(sys.argv[1:] if args is None else args)

	if opts.conf_dump_defaults:
		conf.pprint('Default configuration options', empty_vals=True)
		return

	conf_user_paths = list(map(
		os.path.expanduser, opts.conf or [conf._conf_path] ))
	for n, p in enumerate(conf_user_paths):
		mode = os.R_OK
		if n == len(conf_user_paths) - 1: mode |= os.W_OK
		if not os.access(p, mode):
			parser.error(f'Specified config file missing or inaccessible: {p}')
	conf.read_from_file(*conf_user_paths)

	if opts.conf_dump:
		conf.pprint('Current configuration options')
		return
	if opts.conf_dump_state:
		print('state_timestamps:')
		for v, k in sorted((v,k) for k,v in conf.state.items()):
			print(f'  {k}: {ts_iso8601(v)}')
		return

	if opts.debug: conf.debug_verbose = True
	if opts.debug_log: conf.debug_log_file = opts.debug_log
	if opts.proto_cut: conf.debug_proto_cut = opts.proto_cut
	if opts.proto_log: conf.debug_proto_log_file = opts.proto_log

	log_fmt = '{name} {levelname:5} :: {message}'
	if conf.debug_verbose: log_fmt = '{asctime} :: ' + log_fmt
	log_fmt = logging.Formatter(log_fmt, style='{')
	log_handler = logging.StreamHandler(sys.stderr)
	log_handler.setLevel( logging.DEBUG
		if conf.debug_verbose else logging.WARNING )
	log_handler.setFormatter(log_fmt)
	log_handler.addFilter(log_empty_filter)
	logging.root.addHandler(log_handler)
	logging.root.setLevel(0)
	log = get_logger('main')

	log_handler = LogLevelCounter()
	logging.root.addHandler(log_handler)
	conf._debug_counts = log_handler.counts

	if conf.debug_log_file:
		log_handler = LogFileHandler(
			conf.debug_log_file,
			maxBytes=conf.debug_log_file_size,
			backupCount=conf.debug_log_file_count )
		log_handler.setLevel(logging.DEBUG)
		log_handler.setFormatter(logging.Formatter(
			'{asctime}.{msecs:03d} :: {name} {levelname:5} :: {message}',
			datefmt='%Y-%m-%dT%H:%M:%S', style='{' ))
		logging.root.addHandler(log_handler)

	log_proto = logging.getLogger('proto')
	log_proto.propagate = conf.debug_proto_log_shared
	log_handler = conf._debug_proto = LogFileHandler(
		conf.debug_proto_log_file or '/dev/null',
		maxBytes=conf.debug_proto_log_file_size,
		backupCount=conf.debug_proto_log_file_count )
	log_handler.setLevel( logging.DEBUG
		if conf.debug_proto_log_file else logging.WARNING )
	log_handler.setFormatter(LogProtoFormatter(
		'%(asctime)s :: %(reltime)s :: %(name)s :: %(message)s' ))
	log_proto.addHandler(log_handler)

	def handle_exception(err_t, err, err_tb):
		log.error('Unhandled error: {}', err_fmt(err), exc_info=(err_t, err, err_tb))
	sys.excepthook = handle_exception

	host, port, family = opts.irc_bind or conf.irc_host, conf.irc_port, conf.irc_host_af
	if host.count(':') > 1: host, port = str_part(host, ']:>', port)
	else: host, port = str_part(host, ':>', port)
	if '[' in host: family = socket.AF_INET6
	host, port = host.strip('[]'), int(port)
	try:
		addrinfo = socket.getaddrinfo( host, str(port),
			family=family, type=socket.SOCK_STREAM, proto=socket.IPPROTO_TCP )
		if not addrinfo: raise socket.gaierror('No addrinfo for host: {}'.format(host))
	except (socket.gaierror, socket.error) as err:
		parser.error( 'Failed to resolve irc socket parameters (address, family)'
			' via getaddrinfo: {!r} - [{}] {}'.format((host, port), err.__class__.__name__, err) )
	sock_af, sock_t, sock_p, _, sock_addr = addrinfo[0]
	log.debug(
		'Resolved irc host:port {!r}:{!r} to endpoint: {} (family: {}, type: {}, proto: {})',
		host, port, sock_addr, *(sockopt_resolve(pre, n)
			for pre, n in [('af_', sock_af), ('sock_', sock_t), ('ipproto_', sock_p)]) )
	assert ( sock_t == socket.SOCK_STREAM
		and sock_p == socket.IPPROTO_TCP ), [sock_t, sock_p]
	conf.irc_host_af, (conf.irc_host, conf.irc_port) = sock_af, sock_addr[:2]

	log.debug('Starting eventloop...')
	with contextlib.closing(asyncio.get_event_loop()) as loop:
		if conf.debug_verbose:
			monkey_patch_aiohttp_debug(get_logger('proto.http.reqres'))
			# loop.set_debug(True)
		rdircd = RDIRCD(loop, conf)

		log_handler = conf._debug_chan = LogFuncHandler(rdircd.cmd_log)
		log_handler.setLevel(logging.DEBUG if conf.debug_verbose else logging.INFO)
		log_handler.setFormatter(logging.Formatter(
			'{name} {levelname:5} :: {message}', style='{' ))
		log_handler.addFilter(log_empty_filter)
		logging.root.addHandler(log_handler)

		rdircd_task = loop.create_task(rdircd.run_async())
		for sig in 'INT TERM'.split():
			loop.add_signal_handler(getattr(signal, f'SIG{sig}'), rdircd_task.cancel)
		with contextlib.suppress(asyncio.CancelledError):
			return loop.run_until_complete(rdircd_task)
	log.debug('Finished')

if __name__ == '__main__': sys.exit(main())
